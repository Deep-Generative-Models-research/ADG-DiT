[[34m2024-11-05 11:29:21[0m] Experiment directory created at ./log_EXP/001-dit_g2_full_1024p
[[34m2024-11-05 11:29:21[0m] ['brdit/train_deepspeed.py', '--local_rank=0', '--qk-norm', '--model', 'DiT-g/2', '--rope-img', 'base512', '--rope-real', '--task-flag', 'dit_g2_full_1024p', '--noise-schedule', 'scaled_linear', '--beta-start', '0.00085', '--beta-end', '0.018', '--predict-type', 'v_prediction', '--uncond-p', '0', '--index-file', 'dataset/porcelain/jsons/porcelain.json', '--random-flip', '--lr', '0.0001', '--batch-size', '8', '--image-size', '1024', '--global-seed', '999', '--grad-accu-steps', '1', '--warmup-num-steps', '500', '--use-flash-attn', '--use-fp16', '--extra-fp16', '--results-dir', './log_EXP', '--epochs', '500', '--ckpt-every', '9999999', '--ckpt-latest-every', '9999999', '--ckpt-every-n-epoch', '100', '--log-every', '50', '--deepspeed', '--use-zero-stage', '2', '--gradient-checkpointing', '--cpu-offloading']
[[34m2024-11-05 11:29:21[0m] Namespace(task_flag='dit_g2_full_1024p', batch_size=8, seed=42, use_fp16=True, extra_fp16=True, model='DiT-g/2', image_size=[1024], qk_norm=True, norm='layer', text_states_dim=1024, text_len=77, text_states_dim_t5=2048, text_len_t5=256, training_parts='all', rank=64, lora_ckpt=None, target_modules=['Wqkv', 'q_proj', 'kv_proj', 'out_proj'], output_merge_path=None, control_type='canny', control_weight='1.0', condition_image_path=None, learn_sigma=True, predict_type='v_prediction', noise_schedule='scaled_linear', beta_start=0.00085, beta_end=0.018, sigma_small=False, mse_loss_weight_type='constant', model_var_type=None, noise_offset=0.0, prompt='‰∏ÄÂè™Â∞èÁå´', model_root='ckpts', dit_weight=None, controlnet_weight=None, load_key='ema', use_style_cond=False, size_cond=None, target_ratios=None, cfg_scale=6.0, negative=None, infer_mode='fa', onnx_workdir='onnx_model', sampler='ddpm', infer_steps=100, enhance=True, load_4bit=False, lang='zh', lr=0.0001, epochs=500, max_training_steps=10000000, gc_interval=40, log_every=50, ckpt_every=9999999, ckpt_latest_every=9999999, ckpt_every_n_epoch=100, num_workers=4, global_seed=999, warmup_min_lr=1e-06, warmup_num_steps=500.0, weight_decay=0, rope_img='base512', rope_real=True, uncond_p=0.0, uncond_p_t5=0.2, results_dir='./log_EXP', resume=False, resume_module_root=None, resume_ema_root=None, strict=False, index_file=['dataset/porcelain/jsons/porcelain.json'], random_flip=True, reset_loader=False, multireso=False, reso_step=None, random_shrink_size_cond=False, merge_src_cond=False, use_ema=False, ema_dtype='none', ema_decay=None, ema_warmup=False, ema_warmup_power=None, ema_reset_decay=False, use_flash_attn=True, use_zero_stage=2, grad_accu_steps=1, gradient_checkpointing=True, cpu_offloading=True, save_optimizer_state=False, deepspeed=True, deepspeed_config=None, deepscale=False, deepscale_config=None, deepspeed_mpi=False, local_rank=0, deepspeed_optimizer=False, remote_device='none', zero_stage=1)
[[34m2024-11-05 11:29:21[0m] Building BRDIT Model.
[[34m2024-11-05 11:29:21[0m]     Enable Flash Attention.
[[34m2024-11-05 11:29:21[0m]     Number of tokens: 4096
[[34m2024-11-05 11:29:28[0m]     Using image RoPE (base512) (real): [(0, 0), (32, 32), (64, 64)] | (1024x1024) torch.Size([4096, 88])
[[34m2024-11-05 11:29:28[0m]     Using main model with data type fp16
[[34m2024-11-05 11:29:28[0m]     Loading vae from ckpts/t2i/sdxl-vae-fp16-fix
[[34m2024-11-05 11:29:28[0m]     Loading Bert text encoder from ckpts/t2i/clip_text_encoder
[[34m2024-11-05 11:29:30[0m]     Loading Bert tokenizer from ckpts/t2i/tokenizer
[[34m2024-11-05 11:29:30[0m]     Using fp16 for extra modules: vae, text_encoder
[[34m2024-11-05 11:29:30[0m]     Optimizer parameters: lr=0.0001, weight_decay=0
[[34m2024-11-05 11:29:30[0m]     Using deepspeed optimizer
[[34m2024-11-05 11:29:30[0m] Building Streaming Dataset.
[[34m2024-11-05 11:29:30[0m]     Loading index file ['dataset/porcelain/jsons/porcelain.json'] (v2)
[[34m2024-11-05 11:29:30[0m]     arrow_load_stream | Using ArrowIndexV2: 159
[[34m2024-11-05 11:29:30[0m]     arrow_load_stream | Enable image_meta_size condition (original_size, target_size, crop_coords)
[[34m2024-11-05 11:29:30[0m]     arrow_load_stream | Image_transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.5], std=[0.5])
)
[[34m2024-11-05 11:29:30[0m]     Dataset contains 159 images.
[[34m2024-11-05 11:29:30[0m]     Index file: ['dataset/porcelain/jsons/porcelain.json'].
[[34m2024-11-05 11:29:30[0m] Loading parameter
[[34m2024-11-05 11:29:30[0m]     Training parts: all
[[34m2024-11-05 11:29:30[0m] Initialize deepspeed...
[[34m2024-11-05 11:29:30[0m]     Using deepspeed optimizer
[[34m2024-11-05 11:29:30[0m]     Building scheduler with warmup_min_lr=1e-06, warmup_num_steps=500.0
[[34m2024-11-05 11:29:40[0m]  ****************************** Running training ******************************
[[34m2024-11-05 11:29:40[0m]       Number GPUs:               1
[[34m2024-11-05 11:29:40[0m]       Number training samples:   159
[[34m2024-11-05 11:29:40[0m]       Number parameters:         1,463,500,704
[[34m2024-11-05 11:29:40[0m]       Number trainable params:   1,463,500,704
[[34m2024-11-05 11:29:40[0m]     ------------------------------------------------------------------------------
[[34m2024-11-05 11:29:40[0m]       Iters per epoch:           19
[[34m2024-11-05 11:29:40[0m]       Batch size per device:     8
[[34m2024-11-05 11:29:40[0m]       Batch size all device:     8 (world_size * batch_size * grad_accu_steps)
[[34m2024-11-05 11:29:40[0m]       Gradient Accu steps:       1
[[34m2024-11-05 11:29:40[0m]       Total optimization steps:  9,500
[[34m2024-11-05 11:29:40[0m]       Training epochs:           0/500
[[34m2024-11-05 11:29:40[0m]       Training epoch steps:      0/19
[[34m2024-11-05 11:29:40[0m]       Training total steps:      0/9,500
[[34m2024-11-05 11:29:40[0m]     ------------------------------------------------------------------------------
[[34m2024-11-05 11:29:40[0m]       Noise schedule:            scaled_linear
[[34m2024-11-05 11:29:40[0m]       Beta limits:               (0.00085, 0.018)
[[34m2024-11-05 11:29:40[0m]       Learn sigma:               True
[[34m2024-11-05 11:29:40[0m]       Prediction type:           v_prediction
[[34m2024-11-05 11:29:40[0m]       Noise offset:              0.0
[[34m2024-11-05 11:29:40[0m]     ------------------------------------------------------------------------------
[[34m2024-11-05 11:29:40[0m]       Using EMA model:           False (none)
[[34m2024-11-05 11:29:40[0m]       Using main model fp16:     True
[[34m2024-11-05 11:29:40[0m]       Using extra modules fp16:  True
[[34m2024-11-05 11:29:40[0m]     ------------------------------------------------------------------------------
[[34m2024-11-05 11:29:40[0m]       Experiment directory:      ./log_EXP/001-dit_g2_full_1024p
[[34m2024-11-05 11:29:40[0m]     *******************************************************************************
[[34m2024-11-05 11:29:40[0m]     Start random shuffle with seed=999
[[34m2024-11-05 11:29:40[0m]     End of random shuffle
[[34m2024-11-05 11:29:40[0m]     Beginning epoch 0...
