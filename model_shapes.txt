Keys in the state_dict:
module
buffer_names
optimizer
param_shapes
lr_scheduler
sparse_tensor_module_names
skipped_steps
global_steps
global_samples
dp_world_size
mp_world_size
ds_config
ds_version
steps
epoch
args

Model state parameters and shapes:
pooler.positional_embedding: [78, 1024]
pooler.k_proj.weight: [1024, 1024]
pooler.k_proj.bias: [1024]
pooler.q_proj.weight: [1024, 1024]
pooler.q_proj.bias: [1024]
pooler.v_proj.weight: [1024, 1024]
pooler.v_proj.bias: [1024]
pooler.c_proj.weight: [1024, 1024]
pooler.c_proj.bias: [1024]
x_embedder.proj.weight: [1408, 4, 2, 2]
x_embedder.proj.bias: [1408]
t_embedder.mlp.0.weight: [1408, 256]
t_embedder.mlp.0.bias: [1408]
t_embedder.mlp.2.weight: [1408, 1408]
t_embedder.mlp.2.bias: [1408]
extra_embedder.0.weight: [5632, 1024]
extra_embedder.0.bias: [5632]
extra_embedder.2.weight: [1408, 5632]
extra_embedder.2.bias: [1408]
blocks.0.norm1.weight: [1408]
blocks.0.norm1.bias: [1408]
blocks.0.attn1.Wqkv.weight: [4224, 1408]
blocks.0.attn1.Wqkv.bias: [4224]
blocks.0.attn1.q_norm.weight: [88]
blocks.0.attn1.q_norm.bias: [88]
blocks.0.attn1.k_norm.weight: [88]
blocks.0.attn1.k_norm.bias: [88]
blocks.0.attn1.out_proj.weight: [1408, 1408]
blocks.0.attn1.out_proj.bias: [1408]
blocks.0.norm2.weight: [1408]
blocks.0.norm2.bias: [1408]
blocks.0.mlp.fc1.weight: [6144, 1408]
blocks.0.mlp.fc1.bias: [6144]
blocks.0.mlp.fc2.weight: [1408, 6144]
blocks.0.mlp.fc2.bias: [1408]
blocks.0.default_modulation.1.weight: [1408, 1408]
blocks.0.default_modulation.1.bias: [1408]
blocks.0.attn2.q_proj.weight: [1408, 1408]
blocks.0.attn2.q_proj.bias: [1408]
blocks.0.attn2.kv_proj.weight: [2816, 1024]
blocks.0.attn2.kv_proj.bias: [2816]
blocks.0.attn2.q_norm.weight: [88]
blocks.0.attn2.q_norm.bias: [88]
blocks.0.attn2.k_norm.weight: [88]
blocks.0.attn2.k_norm.bias: [88]
blocks.0.attn2.out_proj.weight: [1408, 1408]
blocks.0.attn2.out_proj.bias: [1408]
blocks.0.norm3.weight: [1408]
blocks.0.norm3.bias: [1408]
blocks.1.norm1.weight: [1408]
blocks.1.norm1.bias: [1408]
blocks.1.attn1.Wqkv.weight: [4224, 1408]
blocks.1.attn1.Wqkv.bias: [4224]
blocks.1.attn1.q_norm.weight: [88]
blocks.1.attn1.q_norm.bias: [88]
blocks.1.attn1.k_norm.weight: [88]
blocks.1.attn1.k_norm.bias: [88]
blocks.1.attn1.out_proj.weight: [1408, 1408]
blocks.1.attn1.out_proj.bias: [1408]
blocks.1.norm2.weight: [1408]
blocks.1.norm2.bias: [1408]
blocks.1.mlp.fc1.weight: [6144, 1408]
blocks.1.mlp.fc1.bias: [6144]
blocks.1.mlp.fc2.weight: [1408, 6144]
blocks.1.mlp.fc2.bias: [1408]
blocks.1.default_modulation.1.weight: [1408, 1408]
blocks.1.default_modulation.1.bias: [1408]
blocks.1.attn2.q_proj.weight: [1408, 1408]
blocks.1.attn2.q_proj.bias: [1408]
blocks.1.attn2.kv_proj.weight: [2816, 1024]
blocks.1.attn2.kv_proj.bias: [2816]
blocks.1.attn2.q_norm.weight: [88]
blocks.1.attn2.q_norm.bias: [88]
blocks.1.attn2.k_norm.weight: [88]
blocks.1.attn2.k_norm.bias: [88]
blocks.1.attn2.out_proj.weight: [1408, 1408]
blocks.1.attn2.out_proj.bias: [1408]
blocks.1.norm3.weight: [1408]
blocks.1.norm3.bias: [1408]
blocks.2.norm1.weight: [1408]
blocks.2.norm1.bias: [1408]
blocks.2.attn1.Wqkv.weight: [4224, 1408]
blocks.2.attn1.Wqkv.bias: [4224]
blocks.2.attn1.q_norm.weight: [88]
blocks.2.attn1.q_norm.bias: [88]
blocks.2.attn1.k_norm.weight: [88]
blocks.2.attn1.k_norm.bias: [88]
blocks.2.attn1.out_proj.weight: [1408, 1408]
blocks.2.attn1.out_proj.bias: [1408]
blocks.2.norm2.weight: [1408]
blocks.2.norm2.bias: [1408]
blocks.2.mlp.fc1.weight: [6144, 1408]
blocks.2.mlp.fc1.bias: [6144]
blocks.2.mlp.fc2.weight: [1408, 6144]
blocks.2.mlp.fc2.bias: [1408]
blocks.2.default_modulation.1.weight: [1408, 1408]
blocks.2.default_modulation.1.bias: [1408]
blocks.2.attn2.q_proj.weight: [1408, 1408]
blocks.2.attn2.q_proj.bias: [1408]
blocks.2.attn2.kv_proj.weight: [2816, 1024]
blocks.2.attn2.kv_proj.bias: [2816]
blocks.2.attn2.q_norm.weight: [88]
blocks.2.attn2.q_norm.bias: [88]
blocks.2.attn2.k_norm.weight: [88]
blocks.2.attn2.k_norm.bias: [88]
blocks.2.attn2.out_proj.weight: [1408, 1408]
blocks.2.attn2.out_proj.bias: [1408]
blocks.2.norm3.weight: [1408]
blocks.2.norm3.bias: [1408]
blocks.3.norm1.weight: [1408]
blocks.3.norm1.bias: [1408]
blocks.3.attn1.Wqkv.weight: [4224, 1408]
blocks.3.attn1.Wqkv.bias: [4224]
blocks.3.attn1.q_norm.weight: [88]
blocks.3.attn1.q_norm.bias: [88]
blocks.3.attn1.k_norm.weight: [88]
blocks.3.attn1.k_norm.bias: [88]
blocks.3.attn1.out_proj.weight: [1408, 1408]
blocks.3.attn1.out_proj.bias: [1408]
blocks.3.norm2.weight: [1408]
blocks.3.norm2.bias: [1408]
blocks.3.mlp.fc1.weight: [6144, 1408]
blocks.3.mlp.fc1.bias: [6144]
blocks.3.mlp.fc2.weight: [1408, 6144]
blocks.3.mlp.fc2.bias: [1408]
blocks.3.default_modulation.1.weight: [1408, 1408]
blocks.3.default_modulation.1.bias: [1408]
blocks.3.attn2.q_proj.weight: [1408, 1408]
blocks.3.attn2.q_proj.bias: [1408]
blocks.3.attn2.kv_proj.weight: [2816, 1024]
blocks.3.attn2.kv_proj.bias: [2816]
blocks.3.attn2.q_norm.weight: [88]
blocks.3.attn2.q_norm.bias: [88]
blocks.3.attn2.k_norm.weight: [88]
blocks.3.attn2.k_norm.bias: [88]
blocks.3.attn2.out_proj.weight: [1408, 1408]
blocks.3.attn2.out_proj.bias: [1408]
blocks.3.norm3.weight: [1408]
blocks.3.norm3.bias: [1408]
blocks.4.norm1.weight: [1408]
blocks.4.norm1.bias: [1408]
blocks.4.attn1.Wqkv.weight: [4224, 1408]
blocks.4.attn1.Wqkv.bias: [4224]
blocks.4.attn1.q_norm.weight: [88]
blocks.4.attn1.q_norm.bias: [88]
blocks.4.attn1.k_norm.weight: [88]
blocks.4.attn1.k_norm.bias: [88]
blocks.4.attn1.out_proj.weight: [1408, 1408]
blocks.4.attn1.out_proj.bias: [1408]
blocks.4.norm2.weight: [1408]
blocks.4.norm2.bias: [1408]
blocks.4.mlp.fc1.weight: [6144, 1408]
blocks.4.mlp.fc1.bias: [6144]
blocks.4.mlp.fc2.weight: [1408, 6144]
blocks.4.mlp.fc2.bias: [1408]
blocks.4.default_modulation.1.weight: [1408, 1408]
blocks.4.default_modulation.1.bias: [1408]
blocks.4.attn2.q_proj.weight: [1408, 1408]
blocks.4.attn2.q_proj.bias: [1408]
blocks.4.attn2.kv_proj.weight: [2816, 1024]
blocks.4.attn2.kv_proj.bias: [2816]
blocks.4.attn2.q_norm.weight: [88]
blocks.4.attn2.q_norm.bias: [88]
blocks.4.attn2.k_norm.weight: [88]
blocks.4.attn2.k_norm.bias: [88]
blocks.4.attn2.out_proj.weight: [1408, 1408]
blocks.4.attn2.out_proj.bias: [1408]
blocks.4.norm3.weight: [1408]
blocks.4.norm3.bias: [1408]
blocks.5.norm1.weight: [1408]
blocks.5.norm1.bias: [1408]
blocks.5.attn1.Wqkv.weight: [4224, 1408]
blocks.5.attn1.Wqkv.bias: [4224]
blocks.5.attn1.q_norm.weight: [88]
blocks.5.attn1.q_norm.bias: [88]
blocks.5.attn1.k_norm.weight: [88]
blocks.5.attn1.k_norm.bias: [88]
blocks.5.attn1.out_proj.weight: [1408, 1408]
blocks.5.attn1.out_proj.bias: [1408]
blocks.5.norm2.weight: [1408]
blocks.5.norm2.bias: [1408]
blocks.5.mlp.fc1.weight: [6144, 1408]
blocks.5.mlp.fc1.bias: [6144]
blocks.5.mlp.fc2.weight: [1408, 6144]
blocks.5.mlp.fc2.bias: [1408]
blocks.5.default_modulation.1.weight: [1408, 1408]
blocks.5.default_modulation.1.bias: [1408]
blocks.5.attn2.q_proj.weight: [1408, 1408]
blocks.5.attn2.q_proj.bias: [1408]
blocks.5.attn2.kv_proj.weight: [2816, 1024]
blocks.5.attn2.kv_proj.bias: [2816]
blocks.5.attn2.q_norm.weight: [88]
blocks.5.attn2.q_norm.bias: [88]
blocks.5.attn2.k_norm.weight: [88]
blocks.5.attn2.k_norm.bias: [88]
blocks.5.attn2.out_proj.weight: [1408, 1408]
blocks.5.attn2.out_proj.bias: [1408]
blocks.5.norm3.weight: [1408]
blocks.5.norm3.bias: [1408]
blocks.6.norm1.weight: [1408]
blocks.6.norm1.bias: [1408]
blocks.6.attn1.Wqkv.weight: [4224, 1408]
blocks.6.attn1.Wqkv.bias: [4224]
blocks.6.attn1.q_norm.weight: [88]
blocks.6.attn1.q_norm.bias: [88]
blocks.6.attn1.k_norm.weight: [88]
blocks.6.attn1.k_norm.bias: [88]
blocks.6.attn1.out_proj.weight: [1408, 1408]
blocks.6.attn1.out_proj.bias: [1408]
blocks.6.norm2.weight: [1408]
blocks.6.norm2.bias: [1408]
blocks.6.mlp.fc1.weight: [6144, 1408]
blocks.6.mlp.fc1.bias: [6144]
blocks.6.mlp.fc2.weight: [1408, 6144]
blocks.6.mlp.fc2.bias: [1408]
blocks.6.default_modulation.1.weight: [1408, 1408]
blocks.6.default_modulation.1.bias: [1408]
blocks.6.attn2.q_proj.weight: [1408, 1408]
blocks.6.attn2.q_proj.bias: [1408]
blocks.6.attn2.kv_proj.weight: [2816, 1024]
blocks.6.attn2.kv_proj.bias: [2816]
blocks.6.attn2.q_norm.weight: [88]
blocks.6.attn2.q_norm.bias: [88]
blocks.6.attn2.k_norm.weight: [88]
blocks.6.attn2.k_norm.bias: [88]
blocks.6.attn2.out_proj.weight: [1408, 1408]
blocks.6.attn2.out_proj.bias: [1408]
blocks.6.norm3.weight: [1408]
blocks.6.norm3.bias: [1408]
blocks.7.norm1.weight: [1408]
blocks.7.norm1.bias: [1408]
blocks.7.attn1.Wqkv.weight: [4224, 1408]
blocks.7.attn1.Wqkv.bias: [4224]
blocks.7.attn1.q_norm.weight: [88]
blocks.7.attn1.q_norm.bias: [88]
blocks.7.attn1.k_norm.weight: [88]
blocks.7.attn1.k_norm.bias: [88]
blocks.7.attn1.out_proj.weight: [1408, 1408]
blocks.7.attn1.out_proj.bias: [1408]
blocks.7.norm2.weight: [1408]
blocks.7.norm2.bias: [1408]
blocks.7.mlp.fc1.weight: [6144, 1408]
blocks.7.mlp.fc1.bias: [6144]
blocks.7.mlp.fc2.weight: [1408, 6144]
blocks.7.mlp.fc2.bias: [1408]
blocks.7.default_modulation.1.weight: [1408, 1408]
blocks.7.default_modulation.1.bias: [1408]
blocks.7.attn2.q_proj.weight: [1408, 1408]
blocks.7.attn2.q_proj.bias: [1408]
blocks.7.attn2.kv_proj.weight: [2816, 1024]
blocks.7.attn2.kv_proj.bias: [2816]
blocks.7.attn2.q_norm.weight: [88]
blocks.7.attn2.q_norm.bias: [88]
blocks.7.attn2.k_norm.weight: [88]
blocks.7.attn2.k_norm.bias: [88]
blocks.7.attn2.out_proj.weight: [1408, 1408]
blocks.7.attn2.out_proj.bias: [1408]
blocks.7.norm3.weight: [1408]
blocks.7.norm3.bias: [1408]
blocks.8.norm1.weight: [1408]
blocks.8.norm1.bias: [1408]
blocks.8.attn1.Wqkv.weight: [4224, 1408]
blocks.8.attn1.Wqkv.bias: [4224]
blocks.8.attn1.q_norm.weight: [88]
blocks.8.attn1.q_norm.bias: [88]
blocks.8.attn1.k_norm.weight: [88]
blocks.8.attn1.k_norm.bias: [88]
blocks.8.attn1.out_proj.weight: [1408, 1408]
blocks.8.attn1.out_proj.bias: [1408]
blocks.8.norm2.weight: [1408]
blocks.8.norm2.bias: [1408]
blocks.8.mlp.fc1.weight: [6144, 1408]
blocks.8.mlp.fc1.bias: [6144]
blocks.8.mlp.fc2.weight: [1408, 6144]
blocks.8.mlp.fc2.bias: [1408]
blocks.8.default_modulation.1.weight: [1408, 1408]
blocks.8.default_modulation.1.bias: [1408]
blocks.8.attn2.q_proj.weight: [1408, 1408]
blocks.8.attn2.q_proj.bias: [1408]
blocks.8.attn2.kv_proj.weight: [2816, 1024]
blocks.8.attn2.kv_proj.bias: [2816]
blocks.8.attn2.q_norm.weight: [88]
blocks.8.attn2.q_norm.bias: [88]
blocks.8.attn2.k_norm.weight: [88]
blocks.8.attn2.k_norm.bias: [88]
blocks.8.attn2.out_proj.weight: [1408, 1408]
blocks.8.attn2.out_proj.bias: [1408]
blocks.8.norm3.weight: [1408]
blocks.8.norm3.bias: [1408]
blocks.9.norm1.weight: [1408]
blocks.9.norm1.bias: [1408]
blocks.9.attn1.Wqkv.weight: [4224, 1408]
blocks.9.attn1.Wqkv.bias: [4224]
blocks.9.attn1.q_norm.weight: [88]
blocks.9.attn1.q_norm.bias: [88]
blocks.9.attn1.k_norm.weight: [88]
blocks.9.attn1.k_norm.bias: [88]
blocks.9.attn1.out_proj.weight: [1408, 1408]
blocks.9.attn1.out_proj.bias: [1408]
blocks.9.norm2.weight: [1408]
blocks.9.norm2.bias: [1408]
blocks.9.mlp.fc1.weight: [6144, 1408]
blocks.9.mlp.fc1.bias: [6144]
blocks.9.mlp.fc2.weight: [1408, 6144]
blocks.9.mlp.fc2.bias: [1408]
blocks.9.default_modulation.1.weight: [1408, 1408]
blocks.9.default_modulation.1.bias: [1408]
blocks.9.attn2.q_proj.weight: [1408, 1408]
blocks.9.attn2.q_proj.bias: [1408]
blocks.9.attn2.kv_proj.weight: [2816, 1024]
blocks.9.attn2.kv_proj.bias: [2816]
blocks.9.attn2.q_norm.weight: [88]
blocks.9.attn2.q_norm.bias: [88]
blocks.9.attn2.k_norm.weight: [88]
blocks.9.attn2.k_norm.bias: [88]
blocks.9.attn2.out_proj.weight: [1408, 1408]
blocks.9.attn2.out_proj.bias: [1408]
blocks.9.norm3.weight: [1408]
blocks.9.norm3.bias: [1408]
blocks.10.norm1.weight: [1408]
blocks.10.norm1.bias: [1408]
blocks.10.attn1.Wqkv.weight: [4224, 1408]
blocks.10.attn1.Wqkv.bias: [4224]
blocks.10.attn1.q_norm.weight: [88]
blocks.10.attn1.q_norm.bias: [88]
blocks.10.attn1.k_norm.weight: [88]
blocks.10.attn1.k_norm.bias: [88]
blocks.10.attn1.out_proj.weight: [1408, 1408]
blocks.10.attn1.out_proj.bias: [1408]
blocks.10.norm2.weight: [1408]
blocks.10.norm2.bias: [1408]
blocks.10.mlp.fc1.weight: [6144, 1408]
blocks.10.mlp.fc1.bias: [6144]
blocks.10.mlp.fc2.weight: [1408, 6144]
blocks.10.mlp.fc2.bias: [1408]
blocks.10.default_modulation.1.weight: [1408, 1408]
blocks.10.default_modulation.1.bias: [1408]
blocks.10.attn2.q_proj.weight: [1408, 1408]
blocks.10.attn2.q_proj.bias: [1408]
blocks.10.attn2.kv_proj.weight: [2816, 1024]
blocks.10.attn2.kv_proj.bias: [2816]
blocks.10.attn2.q_norm.weight: [88]
blocks.10.attn2.q_norm.bias: [88]
blocks.10.attn2.k_norm.weight: [88]
blocks.10.attn2.k_norm.bias: [88]
blocks.10.attn2.out_proj.weight: [1408, 1408]
blocks.10.attn2.out_proj.bias: [1408]
blocks.10.norm3.weight: [1408]
blocks.10.norm3.bias: [1408]
blocks.11.norm1.weight: [1408]
blocks.11.norm1.bias: [1408]
blocks.11.attn1.Wqkv.weight: [4224, 1408]
blocks.11.attn1.Wqkv.bias: [4224]
blocks.11.attn1.q_norm.weight: [88]
blocks.11.attn1.q_norm.bias: [88]
blocks.11.attn1.k_norm.weight: [88]
blocks.11.attn1.k_norm.bias: [88]
blocks.11.attn1.out_proj.weight: [1408, 1408]
blocks.11.attn1.out_proj.bias: [1408]
blocks.11.norm2.weight: [1408]
blocks.11.norm2.bias: [1408]
blocks.11.mlp.fc1.weight: [6144, 1408]
blocks.11.mlp.fc1.bias: [6144]
blocks.11.mlp.fc2.weight: [1408, 6144]
blocks.11.mlp.fc2.bias: [1408]
blocks.11.default_modulation.1.weight: [1408, 1408]
blocks.11.default_modulation.1.bias: [1408]
blocks.11.attn2.q_proj.weight: [1408, 1408]
blocks.11.attn2.q_proj.bias: [1408]
blocks.11.attn2.kv_proj.weight: [2816, 1024]
blocks.11.attn2.kv_proj.bias: [2816]
blocks.11.attn2.q_norm.weight: [88]
blocks.11.attn2.q_norm.bias: [88]
blocks.11.attn2.k_norm.weight: [88]
blocks.11.attn2.k_norm.bias: [88]
blocks.11.attn2.out_proj.weight: [1408, 1408]
blocks.11.attn2.out_proj.bias: [1408]
blocks.11.norm3.weight: [1408]
blocks.11.norm3.bias: [1408]
blocks.12.norm1.weight: [1408]
blocks.12.norm1.bias: [1408]
blocks.12.attn1.Wqkv.weight: [4224, 1408]
blocks.12.attn1.Wqkv.bias: [4224]
blocks.12.attn1.q_norm.weight: [88]
blocks.12.attn1.q_norm.bias: [88]
blocks.12.attn1.k_norm.weight: [88]
blocks.12.attn1.k_norm.bias: [88]
blocks.12.attn1.out_proj.weight: [1408, 1408]
blocks.12.attn1.out_proj.bias: [1408]
blocks.12.norm2.weight: [1408]
blocks.12.norm2.bias: [1408]
blocks.12.mlp.fc1.weight: [6144, 1408]
blocks.12.mlp.fc1.bias: [6144]
blocks.12.mlp.fc2.weight: [1408, 6144]
blocks.12.mlp.fc2.bias: [1408]
blocks.12.default_modulation.1.weight: [1408, 1408]
blocks.12.default_modulation.1.bias: [1408]
blocks.12.attn2.q_proj.weight: [1408, 1408]
blocks.12.attn2.q_proj.bias: [1408]
blocks.12.attn2.kv_proj.weight: [2816, 1024]
blocks.12.attn2.kv_proj.bias: [2816]
blocks.12.attn2.q_norm.weight: [88]
blocks.12.attn2.q_norm.bias: [88]
blocks.12.attn2.k_norm.weight: [88]
blocks.12.attn2.k_norm.bias: [88]
blocks.12.attn2.out_proj.weight: [1408, 1408]
blocks.12.attn2.out_proj.bias: [1408]
blocks.12.norm3.weight: [1408]
blocks.12.norm3.bias: [1408]
blocks.13.norm1.weight: [1408]
blocks.13.norm1.bias: [1408]
blocks.13.attn1.Wqkv.weight: [4224, 1408]
blocks.13.attn1.Wqkv.bias: [4224]
blocks.13.attn1.q_norm.weight: [88]
blocks.13.attn1.q_norm.bias: [88]
blocks.13.attn1.k_norm.weight: [88]
blocks.13.attn1.k_norm.bias: [88]
blocks.13.attn1.out_proj.weight: [1408, 1408]
blocks.13.attn1.out_proj.bias: [1408]
blocks.13.norm2.weight: [1408]
blocks.13.norm2.bias: [1408]
blocks.13.mlp.fc1.weight: [6144, 1408]
blocks.13.mlp.fc1.bias: [6144]
blocks.13.mlp.fc2.weight: [1408, 6144]
blocks.13.mlp.fc2.bias: [1408]
blocks.13.default_modulation.1.weight: [1408, 1408]
blocks.13.default_modulation.1.bias: [1408]
blocks.13.attn2.q_proj.weight: [1408, 1408]
blocks.13.attn2.q_proj.bias: [1408]
blocks.13.attn2.kv_proj.weight: [2816, 1024]
blocks.13.attn2.kv_proj.bias: [2816]
blocks.13.attn2.q_norm.weight: [88]
blocks.13.attn2.q_norm.bias: [88]
blocks.13.attn2.k_norm.weight: [88]
blocks.13.attn2.k_norm.bias: [88]
blocks.13.attn2.out_proj.weight: [1408, 1408]
blocks.13.attn2.out_proj.bias: [1408]
blocks.13.norm3.weight: [1408]
blocks.13.norm3.bias: [1408]
blocks.14.norm1.weight: [1408]
blocks.14.norm1.bias: [1408]
blocks.14.attn1.Wqkv.weight: [4224, 1408]
blocks.14.attn1.Wqkv.bias: [4224]
blocks.14.attn1.q_norm.weight: [88]
blocks.14.attn1.q_norm.bias: [88]
blocks.14.attn1.k_norm.weight: [88]
blocks.14.attn1.k_norm.bias: [88]
blocks.14.attn1.out_proj.weight: [1408, 1408]
blocks.14.attn1.out_proj.bias: [1408]
blocks.14.norm2.weight: [1408]
blocks.14.norm2.bias: [1408]
blocks.14.mlp.fc1.weight: [6144, 1408]
blocks.14.mlp.fc1.bias: [6144]
blocks.14.mlp.fc2.weight: [1408, 6144]
blocks.14.mlp.fc2.bias: [1408]
blocks.14.default_modulation.1.weight: [1408, 1408]
blocks.14.default_modulation.1.bias: [1408]
blocks.14.attn2.q_proj.weight: [1408, 1408]
blocks.14.attn2.q_proj.bias: [1408]
blocks.14.attn2.kv_proj.weight: [2816, 1024]
blocks.14.attn2.kv_proj.bias: [2816]
blocks.14.attn2.q_norm.weight: [88]
blocks.14.attn2.q_norm.bias: [88]
blocks.14.attn2.k_norm.weight: [88]
blocks.14.attn2.k_norm.bias: [88]
blocks.14.attn2.out_proj.weight: [1408, 1408]
blocks.14.attn2.out_proj.bias: [1408]
blocks.14.norm3.weight: [1408]
blocks.14.norm3.bias: [1408]
blocks.15.norm1.weight: [1408]
blocks.15.norm1.bias: [1408]
blocks.15.attn1.Wqkv.weight: [4224, 1408]
blocks.15.attn1.Wqkv.bias: [4224]
blocks.15.attn1.q_norm.weight: [88]
blocks.15.attn1.q_norm.bias: [88]
blocks.15.attn1.k_norm.weight: [88]
blocks.15.attn1.k_norm.bias: [88]
blocks.15.attn1.out_proj.weight: [1408, 1408]
blocks.15.attn1.out_proj.bias: [1408]
blocks.15.norm2.weight: [1408]
blocks.15.norm2.bias: [1408]
blocks.15.mlp.fc1.weight: [6144, 1408]
blocks.15.mlp.fc1.bias: [6144]
blocks.15.mlp.fc2.weight: [1408, 6144]
blocks.15.mlp.fc2.bias: [1408]
blocks.15.default_modulation.1.weight: [1408, 1408]
blocks.15.default_modulation.1.bias: [1408]
blocks.15.attn2.q_proj.weight: [1408, 1408]
blocks.15.attn2.q_proj.bias: [1408]
blocks.15.attn2.kv_proj.weight: [2816, 1024]
blocks.15.attn2.kv_proj.bias: [2816]
blocks.15.attn2.q_norm.weight: [88]
blocks.15.attn2.q_norm.bias: [88]
blocks.15.attn2.k_norm.weight: [88]
blocks.15.attn2.k_norm.bias: [88]
blocks.15.attn2.out_proj.weight: [1408, 1408]
blocks.15.attn2.out_proj.bias: [1408]
blocks.15.norm3.weight: [1408]
blocks.15.norm3.bias: [1408]
blocks.16.norm1.weight: [1408]
blocks.16.norm1.bias: [1408]
blocks.16.attn1.Wqkv.weight: [4224, 1408]
blocks.16.attn1.Wqkv.bias: [4224]
blocks.16.attn1.q_norm.weight: [88]
blocks.16.attn1.q_norm.bias: [88]
blocks.16.attn1.k_norm.weight: [88]
blocks.16.attn1.k_norm.bias: [88]
blocks.16.attn1.out_proj.weight: [1408, 1408]
blocks.16.attn1.out_proj.bias: [1408]
blocks.16.norm2.weight: [1408]
blocks.16.norm2.bias: [1408]
blocks.16.mlp.fc1.weight: [6144, 1408]
blocks.16.mlp.fc1.bias: [6144]
blocks.16.mlp.fc2.weight: [1408, 6144]
blocks.16.mlp.fc2.bias: [1408]
blocks.16.default_modulation.1.weight: [1408, 1408]
blocks.16.default_modulation.1.bias: [1408]
blocks.16.attn2.q_proj.weight: [1408, 1408]
blocks.16.attn2.q_proj.bias: [1408]
blocks.16.attn2.kv_proj.weight: [2816, 1024]
blocks.16.attn2.kv_proj.bias: [2816]
blocks.16.attn2.q_norm.weight: [88]
blocks.16.attn2.q_norm.bias: [88]
blocks.16.attn2.k_norm.weight: [88]
blocks.16.attn2.k_norm.bias: [88]
blocks.16.attn2.out_proj.weight: [1408, 1408]
blocks.16.attn2.out_proj.bias: [1408]
blocks.16.norm3.weight: [1408]
blocks.16.norm3.bias: [1408]
blocks.17.norm1.weight: [1408]
blocks.17.norm1.bias: [1408]
blocks.17.attn1.Wqkv.weight: [4224, 1408]
blocks.17.attn1.Wqkv.bias: [4224]
blocks.17.attn1.q_norm.weight: [88]
blocks.17.attn1.q_norm.bias: [88]
blocks.17.attn1.k_norm.weight: [88]
blocks.17.attn1.k_norm.bias: [88]
blocks.17.attn1.out_proj.weight: [1408, 1408]
blocks.17.attn1.out_proj.bias: [1408]
blocks.17.norm2.weight: [1408]
blocks.17.norm2.bias: [1408]
blocks.17.mlp.fc1.weight: [6144, 1408]
blocks.17.mlp.fc1.bias: [6144]
blocks.17.mlp.fc2.weight: [1408, 6144]
blocks.17.mlp.fc2.bias: [1408]
blocks.17.default_modulation.1.weight: [1408, 1408]
blocks.17.default_modulation.1.bias: [1408]
blocks.17.attn2.q_proj.weight: [1408, 1408]
blocks.17.attn2.q_proj.bias: [1408]
blocks.17.attn2.kv_proj.weight: [2816, 1024]
blocks.17.attn2.kv_proj.bias: [2816]
blocks.17.attn2.q_norm.weight: [88]
blocks.17.attn2.q_norm.bias: [88]
blocks.17.attn2.k_norm.weight: [88]
blocks.17.attn2.k_norm.bias: [88]
blocks.17.attn2.out_proj.weight: [1408, 1408]
blocks.17.attn2.out_proj.bias: [1408]
blocks.17.norm3.weight: [1408]
blocks.17.norm3.bias: [1408]
blocks.18.norm1.weight: [1408]
blocks.18.norm1.bias: [1408]
blocks.18.attn1.Wqkv.weight: [4224, 1408]
blocks.18.attn1.Wqkv.bias: [4224]
blocks.18.attn1.q_norm.weight: [88]
blocks.18.attn1.q_norm.bias: [88]
blocks.18.attn1.k_norm.weight: [88]
blocks.18.attn1.k_norm.bias: [88]
blocks.18.attn1.out_proj.weight: [1408, 1408]
blocks.18.attn1.out_proj.bias: [1408]
blocks.18.norm2.weight: [1408]
blocks.18.norm2.bias: [1408]
blocks.18.mlp.fc1.weight: [6144, 1408]
blocks.18.mlp.fc1.bias: [6144]
blocks.18.mlp.fc2.weight: [1408, 6144]
blocks.18.mlp.fc2.bias: [1408]
blocks.18.default_modulation.1.weight: [1408, 1408]
blocks.18.default_modulation.1.bias: [1408]
blocks.18.attn2.q_proj.weight: [1408, 1408]
blocks.18.attn2.q_proj.bias: [1408]
blocks.18.attn2.kv_proj.weight: [2816, 1024]
blocks.18.attn2.kv_proj.bias: [2816]
blocks.18.attn2.q_norm.weight: [88]
blocks.18.attn2.q_norm.bias: [88]
blocks.18.attn2.k_norm.weight: [88]
blocks.18.attn2.k_norm.bias: [88]
blocks.18.attn2.out_proj.weight: [1408, 1408]
blocks.18.attn2.out_proj.bias: [1408]
blocks.18.norm3.weight: [1408]
blocks.18.norm3.bias: [1408]
blocks.19.norm1.weight: [1408]
blocks.19.norm1.bias: [1408]
blocks.19.attn1.Wqkv.weight: [4224, 1408]
blocks.19.attn1.Wqkv.bias: [4224]
blocks.19.attn1.q_norm.weight: [88]
blocks.19.attn1.q_norm.bias: [88]
blocks.19.attn1.k_norm.weight: [88]
blocks.19.attn1.k_norm.bias: [88]
blocks.19.attn1.out_proj.weight: [1408, 1408]
blocks.19.attn1.out_proj.bias: [1408]
blocks.19.norm2.weight: [1408]
blocks.19.norm2.bias: [1408]
blocks.19.mlp.fc1.weight: [6144, 1408]
blocks.19.mlp.fc1.bias: [6144]
blocks.19.mlp.fc2.weight: [1408, 6144]
blocks.19.mlp.fc2.bias: [1408]
blocks.19.default_modulation.1.weight: [1408, 1408]
blocks.19.default_modulation.1.bias: [1408]
blocks.19.attn2.q_proj.weight: [1408, 1408]
blocks.19.attn2.q_proj.bias: [1408]
blocks.19.attn2.kv_proj.weight: [2816, 1024]
blocks.19.attn2.kv_proj.bias: [2816]
blocks.19.attn2.q_norm.weight: [88]
blocks.19.attn2.q_norm.bias: [88]
blocks.19.attn2.k_norm.weight: [88]
blocks.19.attn2.k_norm.bias: [88]
blocks.19.attn2.out_proj.weight: [1408, 1408]
blocks.19.attn2.out_proj.bias: [1408]
blocks.19.norm3.weight: [1408]
blocks.19.norm3.bias: [1408]
blocks.20.norm1.weight: [1408]
blocks.20.norm1.bias: [1408]
blocks.20.attn1.Wqkv.weight: [4224, 1408]
blocks.20.attn1.Wqkv.bias: [4224]
blocks.20.attn1.q_norm.weight: [88]
blocks.20.attn1.q_norm.bias: [88]
blocks.20.attn1.k_norm.weight: [88]
blocks.20.attn1.k_norm.bias: [88]
blocks.20.attn1.out_proj.weight: [1408, 1408]
blocks.20.attn1.out_proj.bias: [1408]
blocks.20.norm2.weight: [1408]
blocks.20.norm2.bias: [1408]
blocks.20.mlp.fc1.weight: [6144, 1408]
blocks.20.mlp.fc1.bias: [6144]
blocks.20.mlp.fc2.weight: [1408, 6144]
blocks.20.mlp.fc2.bias: [1408]
blocks.20.default_modulation.1.weight: [1408, 1408]
blocks.20.default_modulation.1.bias: [1408]
blocks.20.attn2.q_proj.weight: [1408, 1408]
blocks.20.attn2.q_proj.bias: [1408]
blocks.20.attn2.kv_proj.weight: [2816, 1024]
blocks.20.attn2.kv_proj.bias: [2816]
blocks.20.attn2.q_norm.weight: [88]
blocks.20.attn2.q_norm.bias: [88]
blocks.20.attn2.k_norm.weight: [88]
blocks.20.attn2.k_norm.bias: [88]
blocks.20.attn2.out_proj.weight: [1408, 1408]
blocks.20.attn2.out_proj.bias: [1408]
blocks.20.norm3.weight: [1408]
blocks.20.norm3.bias: [1408]
blocks.21.norm1.weight: [1408]
blocks.21.norm1.bias: [1408]
blocks.21.attn1.Wqkv.weight: [4224, 1408]
blocks.21.attn1.Wqkv.bias: [4224]
blocks.21.attn1.q_norm.weight: [88]
blocks.21.attn1.q_norm.bias: [88]
blocks.21.attn1.k_norm.weight: [88]
blocks.21.attn1.k_norm.bias: [88]
blocks.21.attn1.out_proj.weight: [1408, 1408]
blocks.21.attn1.out_proj.bias: [1408]
blocks.21.norm2.weight: [1408]
blocks.21.norm2.bias: [1408]
blocks.21.mlp.fc1.weight: [6144, 1408]
blocks.21.mlp.fc1.bias: [6144]
blocks.21.mlp.fc2.weight: [1408, 6144]
blocks.21.mlp.fc2.bias: [1408]
blocks.21.default_modulation.1.weight: [1408, 1408]
blocks.21.default_modulation.1.bias: [1408]
blocks.21.attn2.q_proj.weight: [1408, 1408]
blocks.21.attn2.q_proj.bias: [1408]
blocks.21.attn2.kv_proj.weight: [2816, 1024]
blocks.21.attn2.kv_proj.bias: [2816]
blocks.21.attn2.q_norm.weight: [88]
blocks.21.attn2.q_norm.bias: [88]
blocks.21.attn2.k_norm.weight: [88]
blocks.21.attn2.k_norm.bias: [88]
blocks.21.attn2.out_proj.weight: [1408, 1408]
blocks.21.attn2.out_proj.bias: [1408]
blocks.21.norm3.weight: [1408]
blocks.21.norm3.bias: [1408]
blocks.21.skip_norm.weight: [2816]
blocks.21.skip_norm.bias: [2816]
blocks.21.skip_linear.weight: [1408, 2816]
blocks.21.skip_linear.bias: [1408]
blocks.22.norm1.weight: [1408]
blocks.22.norm1.bias: [1408]
blocks.22.attn1.Wqkv.weight: [4224, 1408]
blocks.22.attn1.Wqkv.bias: [4224]
blocks.22.attn1.q_norm.weight: [88]
blocks.22.attn1.q_norm.bias: [88]
blocks.22.attn1.k_norm.weight: [88]
blocks.22.attn1.k_norm.bias: [88]
blocks.22.attn1.out_proj.weight: [1408, 1408]
blocks.22.attn1.out_proj.bias: [1408]
blocks.22.norm2.weight: [1408]
blocks.22.norm2.bias: [1408]
blocks.22.mlp.fc1.weight: [6144, 1408]
blocks.22.mlp.fc1.bias: [6144]
blocks.22.mlp.fc2.weight: [1408, 6144]
blocks.22.mlp.fc2.bias: [1408]
blocks.22.default_modulation.1.weight: [1408, 1408]
blocks.22.default_modulation.1.bias: [1408]
blocks.22.attn2.q_proj.weight: [1408, 1408]
blocks.22.attn2.q_proj.bias: [1408]
blocks.22.attn2.kv_proj.weight: [2816, 1024]
blocks.22.attn2.kv_proj.bias: [2816]
blocks.22.attn2.q_norm.weight: [88]
blocks.22.attn2.q_norm.bias: [88]
blocks.22.attn2.k_norm.weight: [88]
blocks.22.attn2.k_norm.bias: [88]
blocks.22.attn2.out_proj.weight: [1408, 1408]
blocks.22.attn2.out_proj.bias: [1408]
blocks.22.norm3.weight: [1408]
blocks.22.norm3.bias: [1408]
blocks.22.skip_norm.weight: [2816]
blocks.22.skip_norm.bias: [2816]
blocks.22.skip_linear.weight: [1408, 2816]
blocks.22.skip_linear.bias: [1408]
blocks.23.norm1.weight: [1408]
blocks.23.norm1.bias: [1408]
blocks.23.attn1.Wqkv.weight: [4224, 1408]
blocks.23.attn1.Wqkv.bias: [4224]
blocks.23.attn1.q_norm.weight: [88]
blocks.23.attn1.q_norm.bias: [88]
blocks.23.attn1.k_norm.weight: [88]
blocks.23.attn1.k_norm.bias: [88]
blocks.23.attn1.out_proj.weight: [1408, 1408]
blocks.23.attn1.out_proj.bias: [1408]
blocks.23.norm2.weight: [1408]
blocks.23.norm2.bias: [1408]
blocks.23.mlp.fc1.weight: [6144, 1408]
blocks.23.mlp.fc1.bias: [6144]
blocks.23.mlp.fc2.weight: [1408, 6144]
blocks.23.mlp.fc2.bias: [1408]
blocks.23.default_modulation.1.weight: [1408, 1408]
blocks.23.default_modulation.1.bias: [1408]
blocks.23.attn2.q_proj.weight: [1408, 1408]
blocks.23.attn2.q_proj.bias: [1408]
blocks.23.attn2.kv_proj.weight: [2816, 1024]
blocks.23.attn2.kv_proj.bias: [2816]
blocks.23.attn2.q_norm.weight: [88]
blocks.23.attn2.q_norm.bias: [88]
blocks.23.attn2.k_norm.weight: [88]
blocks.23.attn2.k_norm.bias: [88]
blocks.23.attn2.out_proj.weight: [1408, 1408]
blocks.23.attn2.out_proj.bias: [1408]
blocks.23.norm3.weight: [1408]
blocks.23.norm3.bias: [1408]
blocks.23.skip_norm.weight: [2816]
blocks.23.skip_norm.bias: [2816]
blocks.23.skip_linear.weight: [1408, 2816]
blocks.23.skip_linear.bias: [1408]
blocks.24.norm1.weight: [1408]
blocks.24.norm1.bias: [1408]
blocks.24.attn1.Wqkv.weight: [4224, 1408]
blocks.24.attn1.Wqkv.bias: [4224]
blocks.24.attn1.q_norm.weight: [88]
blocks.24.attn1.q_norm.bias: [88]
blocks.24.attn1.k_norm.weight: [88]
blocks.24.attn1.k_norm.bias: [88]
blocks.24.attn1.out_proj.weight: [1408, 1408]
blocks.24.attn1.out_proj.bias: [1408]
blocks.24.norm2.weight: [1408]
blocks.24.norm2.bias: [1408]
blocks.24.mlp.fc1.weight: [6144, 1408]
blocks.24.mlp.fc1.bias: [6144]
blocks.24.mlp.fc2.weight: [1408, 6144]
blocks.24.mlp.fc2.bias: [1408]
blocks.24.default_modulation.1.weight: [1408, 1408]
blocks.24.default_modulation.1.bias: [1408]
blocks.24.attn2.q_proj.weight: [1408, 1408]
blocks.24.attn2.q_proj.bias: [1408]
blocks.24.attn2.kv_proj.weight: [2816, 1024]
blocks.24.attn2.kv_proj.bias: [2816]
blocks.24.attn2.q_norm.weight: [88]
blocks.24.attn2.q_norm.bias: [88]
blocks.24.attn2.k_norm.weight: [88]
blocks.24.attn2.k_norm.bias: [88]
blocks.24.attn2.out_proj.weight: [1408, 1408]
blocks.24.attn2.out_proj.bias: [1408]
blocks.24.norm3.weight: [1408]
blocks.24.norm3.bias: [1408]
blocks.24.skip_norm.weight: [2816]
blocks.24.skip_norm.bias: [2816]
blocks.24.skip_linear.weight: [1408, 2816]
blocks.24.skip_linear.bias: [1408]
blocks.25.norm1.weight: [1408]
blocks.25.norm1.bias: [1408]
blocks.25.attn1.Wqkv.weight: [4224, 1408]
blocks.25.attn1.Wqkv.bias: [4224]
blocks.25.attn1.q_norm.weight: [88]
blocks.25.attn1.q_norm.bias: [88]
blocks.25.attn1.k_norm.weight: [88]
blocks.25.attn1.k_norm.bias: [88]
blocks.25.attn1.out_proj.weight: [1408, 1408]
blocks.25.attn1.out_proj.bias: [1408]
blocks.25.norm2.weight: [1408]
blocks.25.norm2.bias: [1408]
blocks.25.mlp.fc1.weight: [6144, 1408]
blocks.25.mlp.fc1.bias: [6144]
blocks.25.mlp.fc2.weight: [1408, 6144]
blocks.25.mlp.fc2.bias: [1408]
blocks.25.default_modulation.1.weight: [1408, 1408]
blocks.25.default_modulation.1.bias: [1408]
blocks.25.attn2.q_proj.weight: [1408, 1408]
blocks.25.attn2.q_proj.bias: [1408]
blocks.25.attn2.kv_proj.weight: [2816, 1024]
blocks.25.attn2.kv_proj.bias: [2816]
blocks.25.attn2.q_norm.weight: [88]
blocks.25.attn2.q_norm.bias: [88]
blocks.25.attn2.k_norm.weight: [88]
blocks.25.attn2.k_norm.bias: [88]
blocks.25.attn2.out_proj.weight: [1408, 1408]
blocks.25.attn2.out_proj.bias: [1408]
blocks.25.norm3.weight: [1408]
blocks.25.norm3.bias: [1408]
blocks.25.skip_norm.weight: [2816]
blocks.25.skip_norm.bias: [2816]
blocks.25.skip_linear.weight: [1408, 2816]
blocks.25.skip_linear.bias: [1408]
blocks.26.norm1.weight: [1408]
blocks.26.norm1.bias: [1408]
blocks.26.attn1.Wqkv.weight: [4224, 1408]
blocks.26.attn1.Wqkv.bias: [4224]
blocks.26.attn1.q_norm.weight: [88]
blocks.26.attn1.q_norm.bias: [88]
blocks.26.attn1.k_norm.weight: [88]
blocks.26.attn1.k_norm.bias: [88]
blocks.26.attn1.out_proj.weight: [1408, 1408]
blocks.26.attn1.out_proj.bias: [1408]
blocks.26.norm2.weight: [1408]
blocks.26.norm2.bias: [1408]
blocks.26.mlp.fc1.weight: [6144, 1408]
blocks.26.mlp.fc1.bias: [6144]
blocks.26.mlp.fc2.weight: [1408, 6144]
blocks.26.mlp.fc2.bias: [1408]
blocks.26.default_modulation.1.weight: [1408, 1408]
blocks.26.default_modulation.1.bias: [1408]
blocks.26.attn2.q_proj.weight: [1408, 1408]
blocks.26.attn2.q_proj.bias: [1408]
blocks.26.attn2.kv_proj.weight: [2816, 1024]
blocks.26.attn2.kv_proj.bias: [2816]
blocks.26.attn2.q_norm.weight: [88]
blocks.26.attn2.q_norm.bias: [88]
blocks.26.attn2.k_norm.weight: [88]
blocks.26.attn2.k_norm.bias: [88]
blocks.26.attn2.out_proj.weight: [1408, 1408]
blocks.26.attn2.out_proj.bias: [1408]
blocks.26.norm3.weight: [1408]
blocks.26.norm3.bias: [1408]
blocks.26.skip_norm.weight: [2816]
blocks.26.skip_norm.bias: [2816]
blocks.26.skip_linear.weight: [1408, 2816]
blocks.26.skip_linear.bias: [1408]
blocks.27.norm1.weight: [1408]
blocks.27.norm1.bias: [1408]
blocks.27.attn1.Wqkv.weight: [4224, 1408]
blocks.27.attn1.Wqkv.bias: [4224]
blocks.27.attn1.q_norm.weight: [88]
blocks.27.attn1.q_norm.bias: [88]
blocks.27.attn1.k_norm.weight: [88]
blocks.27.attn1.k_norm.bias: [88]
blocks.27.attn1.out_proj.weight: [1408, 1408]
blocks.27.attn1.out_proj.bias: [1408]
blocks.27.norm2.weight: [1408]
blocks.27.norm2.bias: [1408]
blocks.27.mlp.fc1.weight: [6144, 1408]
blocks.27.mlp.fc1.bias: [6144]
blocks.27.mlp.fc2.weight: [1408, 6144]
blocks.27.mlp.fc2.bias: [1408]
blocks.27.default_modulation.1.weight: [1408, 1408]
blocks.27.default_modulation.1.bias: [1408]
blocks.27.attn2.q_proj.weight: [1408, 1408]
blocks.27.attn2.q_proj.bias: [1408]
blocks.27.attn2.kv_proj.weight: [2816, 1024]
blocks.27.attn2.kv_proj.bias: [2816]
blocks.27.attn2.q_norm.weight: [88]
blocks.27.attn2.q_norm.bias: [88]
blocks.27.attn2.k_norm.weight: [88]
blocks.27.attn2.k_norm.bias: [88]
blocks.27.attn2.out_proj.weight: [1408, 1408]
blocks.27.attn2.out_proj.bias: [1408]
blocks.27.norm3.weight: [1408]
blocks.27.norm3.bias: [1408]
blocks.27.skip_norm.weight: [2816]
blocks.27.skip_norm.bias: [2816]
blocks.27.skip_linear.weight: [1408, 2816]
blocks.27.skip_linear.bias: [1408]
blocks.28.norm1.weight: [1408]
blocks.28.norm1.bias: [1408]
blocks.28.attn1.Wqkv.weight: [4224, 1408]
blocks.28.attn1.Wqkv.bias: [4224]
blocks.28.attn1.q_norm.weight: [88]
blocks.28.attn1.q_norm.bias: [88]
blocks.28.attn1.k_norm.weight: [88]
blocks.28.attn1.k_norm.bias: [88]
blocks.28.attn1.out_proj.weight: [1408, 1408]
blocks.28.attn1.out_proj.bias: [1408]
blocks.28.norm2.weight: [1408]
blocks.28.norm2.bias: [1408]
blocks.28.mlp.fc1.weight: [6144, 1408]
blocks.28.mlp.fc1.bias: [6144]
blocks.28.mlp.fc2.weight: [1408, 6144]
blocks.28.mlp.fc2.bias: [1408]
blocks.28.default_modulation.1.weight: [1408, 1408]
blocks.28.default_modulation.1.bias: [1408]
blocks.28.attn2.q_proj.weight: [1408, 1408]
blocks.28.attn2.q_proj.bias: [1408]
blocks.28.attn2.kv_proj.weight: [2816, 1024]
blocks.28.attn2.kv_proj.bias: [2816]
blocks.28.attn2.q_norm.weight: [88]
blocks.28.attn2.q_norm.bias: [88]
blocks.28.attn2.k_norm.weight: [88]
blocks.28.attn2.k_norm.bias: [88]
blocks.28.attn2.out_proj.weight: [1408, 1408]
blocks.28.attn2.out_proj.bias: [1408]
blocks.28.norm3.weight: [1408]
blocks.28.norm3.bias: [1408]
blocks.28.skip_norm.weight: [2816]
blocks.28.skip_norm.bias: [2816]
blocks.28.skip_linear.weight: [1408, 2816]
blocks.28.skip_linear.bias: [1408]
blocks.29.norm1.weight: [1408]
blocks.29.norm1.bias: [1408]
blocks.29.attn1.Wqkv.weight: [4224, 1408]
blocks.29.attn1.Wqkv.bias: [4224]
blocks.29.attn1.q_norm.weight: [88]
blocks.29.attn1.q_norm.bias: [88]
blocks.29.attn1.k_norm.weight: [88]
blocks.29.attn1.k_norm.bias: [88]
blocks.29.attn1.out_proj.weight: [1408, 1408]
blocks.29.attn1.out_proj.bias: [1408]
blocks.29.norm2.weight: [1408]
blocks.29.norm2.bias: [1408]
blocks.29.mlp.fc1.weight: [6144, 1408]
blocks.29.mlp.fc1.bias: [6144]
blocks.29.mlp.fc2.weight: [1408, 6144]
blocks.29.mlp.fc2.bias: [1408]
blocks.29.default_modulation.1.weight: [1408, 1408]
blocks.29.default_modulation.1.bias: [1408]
blocks.29.attn2.q_proj.weight: [1408, 1408]
blocks.29.attn2.q_proj.bias: [1408]
blocks.29.attn2.kv_proj.weight: [2816, 1024]
blocks.29.attn2.kv_proj.bias: [2816]
blocks.29.attn2.q_norm.weight: [88]
blocks.29.attn2.q_norm.bias: [88]
blocks.29.attn2.k_norm.weight: [88]
blocks.29.attn2.k_norm.bias: [88]
blocks.29.attn2.out_proj.weight: [1408, 1408]
blocks.29.attn2.out_proj.bias: [1408]
blocks.29.norm3.weight: [1408]
blocks.29.norm3.bias: [1408]
blocks.29.skip_norm.weight: [2816]
blocks.29.skip_norm.bias: [2816]
blocks.29.skip_linear.weight: [1408, 2816]
blocks.29.skip_linear.bias: [1408]
blocks.30.norm1.weight: [1408]
blocks.30.norm1.bias: [1408]
blocks.30.attn1.Wqkv.weight: [4224, 1408]
blocks.30.attn1.Wqkv.bias: [4224]
blocks.30.attn1.q_norm.weight: [88]
blocks.30.attn1.q_norm.bias: [88]
blocks.30.attn1.k_norm.weight: [88]
blocks.30.attn1.k_norm.bias: [88]
blocks.30.attn1.out_proj.weight: [1408, 1408]
blocks.30.attn1.out_proj.bias: [1408]
blocks.30.norm2.weight: [1408]
blocks.30.norm2.bias: [1408]
blocks.30.mlp.fc1.weight: [6144, 1408]
blocks.30.mlp.fc1.bias: [6144]
blocks.30.mlp.fc2.weight: [1408, 6144]
blocks.30.mlp.fc2.bias: [1408]
blocks.30.default_modulation.1.weight: [1408, 1408]
blocks.30.default_modulation.1.bias: [1408]
blocks.30.attn2.q_proj.weight: [1408, 1408]
blocks.30.attn2.q_proj.bias: [1408]
blocks.30.attn2.kv_proj.weight: [2816, 1024]
blocks.30.attn2.kv_proj.bias: [2816]
blocks.30.attn2.q_norm.weight: [88]
blocks.30.attn2.q_norm.bias: [88]
blocks.30.attn2.k_norm.weight: [88]
blocks.30.attn2.k_norm.bias: [88]
blocks.30.attn2.out_proj.weight: [1408, 1408]
blocks.30.attn2.out_proj.bias: [1408]
blocks.30.norm3.weight: [1408]
blocks.30.norm3.bias: [1408]
blocks.30.skip_norm.weight: [2816]
blocks.30.skip_norm.bias: [2816]
blocks.30.skip_linear.weight: [1408, 2816]
blocks.30.skip_linear.bias: [1408]
blocks.31.norm1.weight: [1408]
blocks.31.norm1.bias: [1408]
blocks.31.attn1.Wqkv.weight: [4224, 1408]
blocks.31.attn1.Wqkv.bias: [4224]
blocks.31.attn1.q_norm.weight: [88]
blocks.31.attn1.q_norm.bias: [88]
blocks.31.attn1.k_norm.weight: [88]
blocks.31.attn1.k_norm.bias: [88]
blocks.31.attn1.out_proj.weight: [1408, 1408]
blocks.31.attn1.out_proj.bias: [1408]
blocks.31.norm2.weight: [1408]
blocks.31.norm2.bias: [1408]
blocks.31.mlp.fc1.weight: [6144, 1408]
blocks.31.mlp.fc1.bias: [6144]
blocks.31.mlp.fc2.weight: [1408, 6144]
blocks.31.mlp.fc2.bias: [1408]
blocks.31.default_modulation.1.weight: [1408, 1408]
blocks.31.default_modulation.1.bias: [1408]
blocks.31.attn2.q_proj.weight: [1408, 1408]
blocks.31.attn2.q_proj.bias: [1408]
blocks.31.attn2.kv_proj.weight: [2816, 1024]
blocks.31.attn2.kv_proj.bias: [2816]
blocks.31.attn2.q_norm.weight: [88]
blocks.31.attn2.q_norm.bias: [88]
blocks.31.attn2.k_norm.weight: [88]
blocks.31.attn2.k_norm.bias: [88]
blocks.31.attn2.out_proj.weight: [1408, 1408]
blocks.31.attn2.out_proj.bias: [1408]
blocks.31.norm3.weight: [1408]
blocks.31.norm3.bias: [1408]
blocks.31.skip_norm.weight: [2816]
blocks.31.skip_norm.bias: [2816]
blocks.31.skip_linear.weight: [1408, 2816]
blocks.31.skip_linear.bias: [1408]
blocks.32.norm1.weight: [1408]
blocks.32.norm1.bias: [1408]
blocks.32.attn1.Wqkv.weight: [4224, 1408]
blocks.32.attn1.Wqkv.bias: [4224]
blocks.32.attn1.q_norm.weight: [88]
blocks.32.attn1.q_norm.bias: [88]
blocks.32.attn1.k_norm.weight: [88]
blocks.32.attn1.k_norm.bias: [88]
blocks.32.attn1.out_proj.weight: [1408, 1408]
blocks.32.attn1.out_proj.bias: [1408]
blocks.32.norm2.weight: [1408]
blocks.32.norm2.bias: [1408]
blocks.32.mlp.fc1.weight: [6144, 1408]
blocks.32.mlp.fc1.bias: [6144]
blocks.32.mlp.fc2.weight: [1408, 6144]
blocks.32.mlp.fc2.bias: [1408]
blocks.32.default_modulation.1.weight: [1408, 1408]
blocks.32.default_modulation.1.bias: [1408]
blocks.32.attn2.q_proj.weight: [1408, 1408]
blocks.32.attn2.q_proj.bias: [1408]
blocks.32.attn2.kv_proj.weight: [2816, 1024]
blocks.32.attn2.kv_proj.bias: [2816]
blocks.32.attn2.q_norm.weight: [88]
blocks.32.attn2.q_norm.bias: [88]
blocks.32.attn2.k_norm.weight: [88]
blocks.32.attn2.k_norm.bias: [88]
blocks.32.attn2.out_proj.weight: [1408, 1408]
blocks.32.attn2.out_proj.bias: [1408]
blocks.32.norm3.weight: [1408]
blocks.32.norm3.bias: [1408]
blocks.32.skip_norm.weight: [2816]
blocks.32.skip_norm.bias: [2816]
blocks.32.skip_linear.weight: [1408, 2816]
blocks.32.skip_linear.bias: [1408]
blocks.33.norm1.weight: [1408]
blocks.33.norm1.bias: [1408]
blocks.33.attn1.Wqkv.weight: [4224, 1408]
blocks.33.attn1.Wqkv.bias: [4224]
blocks.33.attn1.q_norm.weight: [88]
blocks.33.attn1.q_norm.bias: [88]
blocks.33.attn1.k_norm.weight: [88]
blocks.33.attn1.k_norm.bias: [88]
blocks.33.attn1.out_proj.weight: [1408, 1408]
blocks.33.attn1.out_proj.bias: [1408]
blocks.33.norm2.weight: [1408]
blocks.33.norm2.bias: [1408]
blocks.33.mlp.fc1.weight: [6144, 1408]
blocks.33.mlp.fc1.bias: [6144]
blocks.33.mlp.fc2.weight: [1408, 6144]
blocks.33.mlp.fc2.bias: [1408]
blocks.33.default_modulation.1.weight: [1408, 1408]
blocks.33.default_modulation.1.bias: [1408]
blocks.33.attn2.q_proj.weight: [1408, 1408]
blocks.33.attn2.q_proj.bias: [1408]
blocks.33.attn2.kv_proj.weight: [2816, 1024]
blocks.33.attn2.kv_proj.bias: [2816]
blocks.33.attn2.q_norm.weight: [88]
blocks.33.attn2.q_norm.bias: [88]
blocks.33.attn2.k_norm.weight: [88]
blocks.33.attn2.k_norm.bias: [88]
blocks.33.attn2.out_proj.weight: [1408, 1408]
blocks.33.attn2.out_proj.bias: [1408]
blocks.33.norm3.weight: [1408]
blocks.33.norm3.bias: [1408]
blocks.33.skip_norm.weight: [2816]
blocks.33.skip_norm.bias: [2816]
blocks.33.skip_linear.weight: [1408, 2816]
blocks.33.skip_linear.bias: [1408]
blocks.34.norm1.weight: [1408]
blocks.34.norm1.bias: [1408]
blocks.34.attn1.Wqkv.weight: [4224, 1408]
blocks.34.attn1.Wqkv.bias: [4224]
blocks.34.attn1.q_norm.weight: [88]
blocks.34.attn1.q_norm.bias: [88]
blocks.34.attn1.k_norm.weight: [88]
blocks.34.attn1.k_norm.bias: [88]
blocks.34.attn1.out_proj.weight: [1408, 1408]
blocks.34.attn1.out_proj.bias: [1408]
blocks.34.norm2.weight: [1408]
blocks.34.norm2.bias: [1408]
blocks.34.mlp.fc1.weight: [6144, 1408]
blocks.34.mlp.fc1.bias: [6144]
blocks.34.mlp.fc2.weight: [1408, 6144]
blocks.34.mlp.fc2.bias: [1408]
blocks.34.default_modulation.1.weight: [1408, 1408]
blocks.34.default_modulation.1.bias: [1408]
blocks.34.attn2.q_proj.weight: [1408, 1408]
blocks.34.attn2.q_proj.bias: [1408]
blocks.34.attn2.kv_proj.weight: [2816, 1024]
blocks.34.attn2.kv_proj.bias: [2816]
blocks.34.attn2.q_norm.weight: [88]
blocks.34.attn2.q_norm.bias: [88]
blocks.34.attn2.k_norm.weight: [88]
blocks.34.attn2.k_norm.bias: [88]
blocks.34.attn2.out_proj.weight: [1408, 1408]
blocks.34.attn2.out_proj.bias: [1408]
blocks.34.norm3.weight: [1408]
blocks.34.norm3.bias: [1408]
blocks.34.skip_norm.weight: [2816]
blocks.34.skip_norm.bias: [2816]
blocks.34.skip_linear.weight: [1408, 2816]
blocks.34.skip_linear.bias: [1408]
blocks.35.norm1.weight: [1408]
blocks.35.norm1.bias: [1408]
blocks.35.attn1.Wqkv.weight: [4224, 1408]
blocks.35.attn1.Wqkv.bias: [4224]
blocks.35.attn1.q_norm.weight: [88]
blocks.35.attn1.q_norm.bias: [88]
blocks.35.attn1.k_norm.weight: [88]
blocks.35.attn1.k_norm.bias: [88]
blocks.35.attn1.out_proj.weight: [1408, 1408]
blocks.35.attn1.out_proj.bias: [1408]
blocks.35.norm2.weight: [1408]
blocks.35.norm2.bias: [1408]
blocks.35.mlp.fc1.weight: [6144, 1408]
blocks.35.mlp.fc1.bias: [6144]
blocks.35.mlp.fc2.weight: [1408, 6144]
blocks.35.mlp.fc2.bias: [1408]
blocks.35.default_modulation.1.weight: [1408, 1408]
blocks.35.default_modulation.1.bias: [1408]
blocks.35.attn2.q_proj.weight: [1408, 1408]
blocks.35.attn2.q_proj.bias: [1408]
blocks.35.attn2.kv_proj.weight: [2816, 1024]
blocks.35.attn2.kv_proj.bias: [2816]
blocks.35.attn2.q_norm.weight: [88]
blocks.35.attn2.q_norm.bias: [88]
blocks.35.attn2.k_norm.weight: [88]
blocks.35.attn2.k_norm.bias: [88]
blocks.35.attn2.out_proj.weight: [1408, 1408]
blocks.35.attn2.out_proj.bias: [1408]
blocks.35.norm3.weight: [1408]
blocks.35.norm3.bias: [1408]
blocks.35.skip_norm.weight: [2816]
blocks.35.skip_norm.bias: [2816]
blocks.35.skip_linear.weight: [1408, 2816]
blocks.35.skip_linear.bias: [1408]
blocks.36.norm1.weight: [1408]
blocks.36.norm1.bias: [1408]
blocks.36.attn1.Wqkv.weight: [4224, 1408]
blocks.36.attn1.Wqkv.bias: [4224]
blocks.36.attn1.q_norm.weight: [88]
blocks.36.attn1.q_norm.bias: [88]
blocks.36.attn1.k_norm.weight: [88]
blocks.36.attn1.k_norm.bias: [88]
blocks.36.attn1.out_proj.weight: [1408, 1408]
blocks.36.attn1.out_proj.bias: [1408]
blocks.36.norm2.weight: [1408]
blocks.36.norm2.bias: [1408]
blocks.36.mlp.fc1.weight: [6144, 1408]
blocks.36.mlp.fc1.bias: [6144]
blocks.36.mlp.fc2.weight: [1408, 6144]
blocks.36.mlp.fc2.bias: [1408]
blocks.36.default_modulation.1.weight: [1408, 1408]
blocks.36.default_modulation.1.bias: [1408]
blocks.36.attn2.q_proj.weight: [1408, 1408]
blocks.36.attn2.q_proj.bias: [1408]
blocks.36.attn2.kv_proj.weight: [2816, 1024]
blocks.36.attn2.kv_proj.bias: [2816]
blocks.36.attn2.q_norm.weight: [88]
blocks.36.attn2.q_norm.bias: [88]
blocks.36.attn2.k_norm.weight: [88]
blocks.36.attn2.k_norm.bias: [88]
blocks.36.attn2.out_proj.weight: [1408, 1408]
blocks.36.attn2.out_proj.bias: [1408]
blocks.36.norm3.weight: [1408]
blocks.36.norm3.bias: [1408]
blocks.36.skip_norm.weight: [2816]
blocks.36.skip_norm.bias: [2816]
blocks.36.skip_linear.weight: [1408, 2816]
blocks.36.skip_linear.bias: [1408]
blocks.37.norm1.weight: [1408]
blocks.37.norm1.bias: [1408]
blocks.37.attn1.Wqkv.weight: [4224, 1408]
blocks.37.attn1.Wqkv.bias: [4224]
blocks.37.attn1.q_norm.weight: [88]
blocks.37.attn1.q_norm.bias: [88]
blocks.37.attn1.k_norm.weight: [88]
blocks.37.attn1.k_norm.bias: [88]
blocks.37.attn1.out_proj.weight: [1408, 1408]
blocks.37.attn1.out_proj.bias: [1408]
blocks.37.norm2.weight: [1408]
blocks.37.norm2.bias: [1408]
blocks.37.mlp.fc1.weight: [6144, 1408]
blocks.37.mlp.fc1.bias: [6144]
blocks.37.mlp.fc2.weight: [1408, 6144]
blocks.37.mlp.fc2.bias: [1408]
blocks.37.default_modulation.1.weight: [1408, 1408]
blocks.37.default_modulation.1.bias: [1408]
blocks.37.attn2.q_proj.weight: [1408, 1408]
blocks.37.attn2.q_proj.bias: [1408]
blocks.37.attn2.kv_proj.weight: [2816, 1024]
blocks.37.attn2.kv_proj.bias: [2816]
blocks.37.attn2.q_norm.weight: [88]
blocks.37.attn2.q_norm.bias: [88]
blocks.37.attn2.k_norm.weight: [88]
blocks.37.attn2.k_norm.bias: [88]
blocks.37.attn2.out_proj.weight: [1408, 1408]
blocks.37.attn2.out_proj.bias: [1408]
blocks.37.norm3.weight: [1408]
blocks.37.norm3.bias: [1408]
blocks.37.skip_norm.weight: [2816]
blocks.37.skip_norm.bias: [2816]
blocks.37.skip_linear.weight: [1408, 2816]
blocks.37.skip_linear.bias: [1408]
blocks.38.norm1.weight: [1408]
blocks.38.norm1.bias: [1408]
blocks.38.attn1.Wqkv.weight: [4224, 1408]
blocks.38.attn1.Wqkv.bias: [4224]
blocks.38.attn1.q_norm.weight: [88]
blocks.38.attn1.q_norm.bias: [88]
blocks.38.attn1.k_norm.weight: [88]
blocks.38.attn1.k_norm.bias: [88]
blocks.38.attn1.out_proj.weight: [1408, 1408]
blocks.38.attn1.out_proj.bias: [1408]
blocks.38.norm2.weight: [1408]
blocks.38.norm2.bias: [1408]
blocks.38.mlp.fc1.weight: [6144, 1408]
blocks.38.mlp.fc1.bias: [6144]
blocks.38.mlp.fc2.weight: [1408, 6144]
blocks.38.mlp.fc2.bias: [1408]
blocks.38.default_modulation.1.weight: [1408, 1408]
blocks.38.default_modulation.1.bias: [1408]
blocks.38.attn2.q_proj.weight: [1408, 1408]
blocks.38.attn2.q_proj.bias: [1408]
blocks.38.attn2.kv_proj.weight: [2816, 1024]
blocks.38.attn2.kv_proj.bias: [2816]
blocks.38.attn2.q_norm.weight: [88]
blocks.38.attn2.q_norm.bias: [88]
blocks.38.attn2.k_norm.weight: [88]
blocks.38.attn2.k_norm.bias: [88]
blocks.38.attn2.out_proj.weight: [1408, 1408]
blocks.38.attn2.out_proj.bias: [1408]
blocks.38.norm3.weight: [1408]
blocks.38.norm3.bias: [1408]
blocks.38.skip_norm.weight: [2816]
blocks.38.skip_norm.bias: [2816]
blocks.38.skip_linear.weight: [1408, 2816]
blocks.38.skip_linear.bias: [1408]
blocks.39.norm1.weight: [1408]
blocks.39.norm1.bias: [1408]
blocks.39.attn1.Wqkv.weight: [4224, 1408]
blocks.39.attn1.Wqkv.bias: [4224]
blocks.39.attn1.q_norm.weight: [88]
blocks.39.attn1.q_norm.bias: [88]
blocks.39.attn1.k_norm.weight: [88]
blocks.39.attn1.k_norm.bias: [88]
blocks.39.attn1.out_proj.weight: [1408, 1408]
blocks.39.attn1.out_proj.bias: [1408]
blocks.39.norm2.weight: [1408]
blocks.39.norm2.bias: [1408]
blocks.39.mlp.fc1.weight: [6144, 1408]
blocks.39.mlp.fc1.bias: [6144]
blocks.39.mlp.fc2.weight: [1408, 6144]
blocks.39.mlp.fc2.bias: [1408]
blocks.39.default_modulation.1.weight: [1408, 1408]
blocks.39.default_modulation.1.bias: [1408]
blocks.39.attn2.q_proj.weight: [1408, 1408]
blocks.39.attn2.q_proj.bias: [1408]
blocks.39.attn2.kv_proj.weight: [2816, 1024]
blocks.39.attn2.kv_proj.bias: [2816]
blocks.39.attn2.q_norm.weight: [88]
blocks.39.attn2.q_norm.bias: [88]
blocks.39.attn2.k_norm.weight: [88]
blocks.39.attn2.k_norm.bias: [88]
blocks.39.attn2.out_proj.weight: [1408, 1408]
blocks.39.attn2.out_proj.bias: [1408]
blocks.39.norm3.weight: [1408]
blocks.39.norm3.bias: [1408]
blocks.39.skip_norm.weight: [2816]
blocks.39.skip_norm.bias: [2816]
blocks.39.skip_linear.weight: [1408, 2816]
blocks.39.skip_linear.bias: [1408]
final_layer.linear.weight: [32, 1408]
final_layer.linear.bias: [32]
final_layer.adaLN_modulation.1.weight: [2816, 1408]
final_layer.adaLN_modulation.1.bias: [2816]
